{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c511fda7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TrainingVisualizer' from 'utils.utils' (e:\\Radar and RGB Camera Sensor Fusion\\nuScenes Dataset\\utils\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProbabilisticLoss\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, dataLoader\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingVisualizer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TrainingVisualizer' from 'utils.utils' (e:\\Radar and RGB Camera Sensor Fusion\\nuScenes Dataset\\utils\\utils.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, RadarPointCloud\n",
    "from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
    "from pyquaternion import Quaternion\n",
    "import cv2\n",
    "\n",
    "from YOLORadarModel import ProbabilisticYOLORadar3D\n",
    "from losses import ProbabilisticLoss\n",
    "from utils import utils, dataLoader\n",
    "from utils.utils import TrainingVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a536b",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "├── Front Camera Image (900×1600×3) at time t\n",
    "└── Front Radar Point Cloud (N×5) with timestamps [t-Δt to t]\n",
    "    ↓\n",
    "Probabilistic Radar Processing\n",
    "├── Temporal Alignment & Uncertainty Modeling\n",
    "├── 3D Gaussian Sphere Generation\n",
    "└── Uncertainty-Aware Feature Encoding\n",
    "    ↓\n",
    "Feature Extraction (Dual Branch)\n",
    "├── Image Branch: Modified YOLOv8 Backbone\n",
    "└── Radar Branch: Probabilistic PointNet Encoder\n",
    "    ↓\n",
    "Uncertainty-Aware Fusion Module\n",
    "    ↓\n",
    "Modified Neck (FPN + PAN)\n",
    "    ↓\n",
    "3D Detection Head with Uncertainty Estimation\n",
    "├── 2D Box Regression\n",
    "├── 3D Box Regression (center, dimensions, rotation)\n",
    "├── Depth Estimation + Uncertainty\n",
    "├── Velocity Estimation + Uncertainty\n",
    "└── Classification with Confidence\n",
    "    ↓\n",
    "Outputs: [class, 2D box, 3D center, 3D dims, yaw, velocity] \n",
    "         + [uncertainties for each prediction]\n",
    "\n",
    "Radar Point Representation:\n",
    "├── Mean (μ): (x, y, z, vx, vy) - measured values\n",
    "├── Covariance (Σ): 5×5 matrix - measurement uncertainty\n",
    "├── Temporal offset: Δt = t_image - t_radar\n",
    "└── Radar Cross Section (RCS): measurement confidence\n",
    "\n",
    "Gaussian Parameters per point:\n",
    "├── Position uncertainty: σ_pos (from range accuracy)\n",
    "├── Velocity uncertainty: σ_vel (from Doppler accuracy)  \n",
    "├── Temporal uncertainty: σ_temp (from time difference)\n",
    "└── RCS-based confidence: weight = f(RCS)\n",
    "\n",
    "For each radar point at time (t - Δt):\n",
    "\n",
    "1. Ego Motion Compensation:\n",
    "   p_compensated = p_measured - ego_velocity × Δt\n",
    "   \n",
    "2. Temporal Uncertainty Propagation:\n",
    "   σ_temporal² = σ_vel² × (Δt)²\n",
    "   \n",
    "3. Combined Position Uncertainty:\n",
    "   Σ_pos = [\n",
    "       [σ_x² + σ_temporal², 0, 0],\n",
    "       [0, σ_y² + σ_temporal², 0],\n",
    "       [0, 0, σ_z²]\n",
    "   ]\n",
    "   \n",
    "4. Velocity Uncertainty (considering time lag):\n",
    "   Σ_vel = [\n",
    "       [σ_vx² + k×Δt, 0],\n",
    "       [0, σ_vy² + k×Δt]\n",
    "   ]\n",
    "   where k is uncertainty growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2dceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    \n",
    "    # ========== Configuration ==========\n",
    "    config = {\n",
    "        'dataroot': '/data/sets/nuscenes',\n",
    "        'version': 'v1.0-trainval',  # or 'v1.0-mini' for testing\n",
    "        'batch_size': 4,\n",
    "        'num_workers': 8,\n",
    "        'num_epochs': 100,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'image_size': (640, 640),\n",
    "        'max_radar_points': 1000,\n",
    "        'save_dir': './checkpoints',\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'resume': None,  # Path to checkpoint to resume from\n",
    "    }\n",
    "    \n",
    "    print(\"Configuration:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Create save directory\n",
    "    os.makedirs(config['save_dir'], exist_ok=True)\n",
    "    \n",
    "    # Save config\n",
    "    with open(os.path.join(config['save_dir'], 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # ========== Create Datasets ==========\n",
    "    print(\"\\nCreating datasets...\")\n",
    "    train_dataset = dataLoader.NuScenesRadarDataset(\n",
    "        dataroot=config['dataroot'],\n",
    "        version=config['version'],\n",
    "        split='train',\n",
    "        image_size=config['image_size'],\n",
    "        max_radar_points=config['max_radar_points']\n",
    "    )\n",
    "    \n",
    "    val_dataset = dataLoader.NuScenesRadarDataset(\n",
    "        dataroot=config['dataroot'],\n",
    "        version=config['version'],\n",
    "        split='val',\n",
    "        image_size=config['image_size'],\n",
    "        max_radar_points=config['max_radar_points']\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers'],\n",
    "        collate_fn=utils.collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers'],\n",
    "        collate_fn=utils.collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ========== Create Model ==========\n",
    "    print(\"\\nCreating model...\")\n",
    "    model = ProbabilisticYOLORadar3D(num_classes=10)\n",
    "    model = model.to(config['device'])\n",
    "    \n",
    "    # Count parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model parameters: {num_params:,}\")\n",
    "    \n",
    "    # ========== Create Optimizer and Loss ==========\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': model.image_backbone.parameters(), 'lr': config['learning_rate'] * 0.1},\n",
    "        {'params': model.radar_branch.parameters(), 'lr': config['learning_rate']},\n",
    "        {'params': model.fusion_p3.parameters(), 'lr': config['learning_rate']},\n",
    "        {'params': model.fusion_p4.parameters(), 'lr': config['learning_rate']},\n",
    "        {'params': model.fusion_p5.parameters(), 'lr': config['learning_rate']},\n",
    "        {'params': model.head_3d.parameters(), 'lr': config['learning_rate']},\n",
    "    ], weight_decay=config['weight_decay'])\n",
    "    \n",
    "    criterion = ProbabilisticLoss(\n",
    "        loss_weights={\n",
    "            'cls': 1.0,\n",
    "            'box_2d': 2.0,\n",
    "            'depth': 2.0,\n",
    "            'center': 2.0,\n",
    "            'dims': 1.0,\n",
    "            'rot': 0.5,\n",
    "            'vel': 1.5,\n",
    "            'uncertainty_reg': 0.1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config['num_epochs'],\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # Resume from checkpoint\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if config['resume']:\n",
    "        print(f\"\\nResuming from checkpoint: {config['resume']}\")\n",
    "        checkpoint = utils.load_checkpoint(config['resume'])\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "    \n",
    "    viz = utils.TrainingVisualizer(save_dir='./logs', experiment_name = 'test_run')\n",
    "    # ========== Training Loop ==========\n",
    "    print(\"\\nStarting training...\")\n",
    "    \n",
    "    for epoch in range(start_epoch, config['num_epochs']):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch}/{config['num_epochs']-1}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = utils.train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, config['device'], epoch\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss = utils.validate(model, val_loader, criterion, config['device'])\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        viz.log_epoch(epoch, train_loss, val_loss, scheduler.get_last_lr())\n",
    "        print(f\"\\nEpoch {epoch} Summary:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'config': config\n",
    "        }\n",
    "        \n",
    "        # Save last checkpoint\n",
    "        utils.save_checkpoint(\n",
    "            checkpoint,\n",
    "            os.path.join(config['save_dir'], 'last.pth')\n",
    "        )\n",
    "        \n",
    "        # Save best checkpoint\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            checkpoint['best_val_loss'] = best_val_loss\n",
    "            utils.save_checkpoint(\n",
    "                checkpoint,\n",
    "                os.path.join(config['save_dir'], 'best.pth')\n",
    "            )\n",
    "            print(f\"  New best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Save periodic checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            utils.save_checkpoint(\n",
    "                checkpoint,\n",
    "                os.path.join(config['save_dir'], f'epoch_{epoch}.pth')\n",
    "            )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training completed!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    viz.plot_summary()\n",
    "    viz.generate_report()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7dbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Total parameters: 74,958,695\n",
      "\n",
      "Running forward pass...\n",
      "\n",
      "Output shapes:\n",
      "  cls: torch.Size([2, 10, 80, 80])\n",
      "  box_2d: torch.Size([2, 4, 80, 80])\n",
      "  depth_mean: torch.Size([2, 1, 80, 80])\n",
      "  depth_std: torch.Size([2, 1, 80, 80])\n",
      "  center_offset: torch.Size([2, 2, 80, 80])\n",
      "  dims_mean: torch.Size([2, 3, 80, 80])\n",
      "  rot_mean: torch.Size([2, 2, 80, 80])\n",
      "  vel_mean: torch.Size([2, 2, 80, 80])\n",
      "  vel_std: torch.Size([2, 2, 80, 80])\n",
      "  fusion_weights: dict with 3 items\n",
      "\n",
      "✓ Model test passed!\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "    \n",
    "model = ProbabilisticYOLORadar3D(num_classes=10).to(device)\n",
    "    \n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {num_params:,}\")\n",
    "    \n",
    "# Test forward pass\n",
    "batch_size = 2\n",
    "image = torch.randn(batch_size, 3, 640, 640).to(device)\n",
    "radar_points = torch.randn(batch_size, 1000, 6).to(device)\n",
    "radar_timestamps = torch.zeros(batch_size, 1000).to(device)\n",
    "calib = [None] * batch_size\n",
    "    \n",
    "print(\"\\nRunning forward pass...\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(image, radar_points, radar_timestamps, calib)\n",
    "    \n",
    "print(\"\\nOutput shapes:\")\n",
    "for key, value in outputs.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: {value.shape}\")\n",
    "    elif isinstance(value, dict):\n",
    "        print(f\"  {key}: dict with {len(value)} items\")\n",
    "    \n",
    "print(\"\\nModel test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4096c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils.utils' has no attribute 'TrainingVisualizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create visualizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m viz \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingVisualizer\u001b[49m(save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m, experiment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Simulate training for demo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulating training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'utils.utils' has no attribute 'TrainingVisualizer'"
     ]
    }
   ],
   "source": [
    " # Create visualizer\n",
    "viz = TrainingVisualizer(save_dir='./logs', experiment_name='test_run')\n",
    "    \n",
    "# Simulate training for demo\n",
    "print(\"Simulating training...\")\n",
    "for epoch in range(50):\n",
    "    # Fake losses that improve over time\n",
    "    train_total = 5.0 * np.exp(-epoch/20) + np.random.normal(0, 0.1)\n",
    "    val_loss = 4.8 * np.exp(-epoch/20) + np.random.normal(0, 0.15)\n",
    "        \n",
    "    train_losses = {\n",
    "        'total': train_total,\n",
    "        'cls': train_total * 0.3,\n",
    "        'box_2d': train_total * 0.25,\n",
    "        'depth': train_total * 0.25,\n",
    "        'vel': train_total * 0.2\n",
    "    }\n",
    "        \n",
    "    lr = 1e-4 * (0.95 ** epoch)\n",
    "        \n",
    "    viz.log_epoch(epoch, train_losses, val_loss, lr)\n",
    "    \n",
    "# Generate all plots\n",
    "viz.plot_summary()\n",
    "viz.generate_report()\n",
    "    \n",
    "print(\"\\n✓ Visualizer test completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
